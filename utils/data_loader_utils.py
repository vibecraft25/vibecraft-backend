__author__ = "Se Hoon Kim(sehoon787@korea.ac.kr)"

# Standard imports
import os
from datetime import datetime
from typing import List, Optional
import json
import sqlite3
import ast

# Third-party imports
import pandas as pd
import chardet


def load_files() -> pd.DataFrame:
    print("\nğŸ“ CSV ë˜ëŠ” SQLite íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì‰¼í‘œ(,)ë¡œ ì—¬ëŸ¬ ê°œ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    file_input = input("íŒŒì¼ ê²½ë¡œë“¤: ").strip()
    paths = [path.strip() for path in file_input.split(",")]
    return load_local_files(paths)


def detect_file_encoding(path: str, num_bytes: int = 10000) -> str:
    with open(path, 'rb') as f:
        raw_data = f.read(num_bytes)
    result = chardet.detect(raw_data)
    return result['encoding'] or 'utf-8'


def load_local_files(file_paths: List[str]) -> Optional[pd.DataFrame]:
    dataframes = []
    for path in file_paths:
        if not os.path.exists(path):
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {path}")
            continue
        try:
            if path.endswith(".csv"):
                encoding = detect_file_encoding(path)
                df_part = pd.read_csv(path, encoding=encoding)
            elif path.endswith(".sqlite") or path.endswith(".db"):
                with sqlite3.connect(path) as conn:
                    tables = pd.read_sql("SELECT name FROM sqlite_master WHERE type='table';", conn)
                    table_name = tables['name'].iloc[0]
                    df_part = pd.read_sql(f"SELECT * FROM {table_name}", conn)
            else:
                print(f"âš ï¸ ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {path}")
                continue
            dataframes.append(df_part)
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e} (íŒŒì¼: {path})")
    if dataframes:
        return pd.concat(dataframes, ignore_index=True)
    return None


def markdown_table_to_df(text: str) -> Optional[pd.DataFrame]:
    try:
        # í…ìŠ¤íŠ¸ì—ì„œ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ë¶€ë¶„ë§Œ ì¶”ì¶œ
        lines = text.strip().split('\n')

        # í…Œì´ë¸” ì‹œì‘ê³¼ ë ì°¾ê¸°
        table_lines = []
        in_table = False

        for line in lines:
            line = line.strip()
            if '|' in line:
                if not in_table:
                    in_table = True
                    table_lines.append(line)
                elif '---' in line:  # êµ¬ë¶„ì„ ì€ ê±´ë„ˆë›°ê¸°
                    continue
                else:
                    table_lines.append(line)
            elif in_table:
                # í…Œì´ë¸”ì´ ëë‚¬ìœ¼ë©´ ì¤‘ë‹¨
                break

        if len(table_lines) < 2:
            raise ValueError("ìœ íš¨í•œ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # íŒŒì´í”„ ì •ë¦¬ ë° ë°ì´í„° ì¤€ë¹„
        cleaned_lines = []
        for line in table_lines:
            # ì–‘ìª½ ë íŒŒì´í”„ ì œê±° ë° ë‚´ë¶€ íŒŒì´í”„ë¡œ ë¶„í• 
            if line.startswith('|'):
                line = line[1:]
            if line.endswith('|'):
                line = line[:-1]

            # ì…€ë“¤ì„ ë¶„í• í•˜ê³  ê³µë°± ì œê±°
            cells = [cell.strip() for cell in line.split('|')]
            cleaned_lines.append(cells)

        # DataFrame ìƒì„±
        if len(cleaned_lines) > 0:
            headers = cleaned_lines[0]
            data = cleaned_lines[1:] if len(cleaned_lines) > 1 else []

            # ëª¨ë“  í–‰ì˜ ì»¬ëŸ¼ ìˆ˜ë¥¼ í—¤ë”ì™€ ë§ì¶”ê¸°
            for i, row in enumerate(data):
                if len(row) < len(headers):
                    data[i].extend([''] * (len(headers) - len(row)))
                elif len(row) > len(headers):
                    data[i] = row[:len(headers)]

            df = pd.DataFrame(data, columns=headers)

            # ë¹ˆ í–‰ ì œê±°
            df = df.dropna(how='all').reset_index(drop=True)

            print(f"âœ… ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ë¨: {len(df)} í–‰, {len(df.columns)} ì»¬ëŸ¼")
            return df
        else:
            raise ValueError("í…Œì´ë¸” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âš ï¸ ìƒ˜í”Œ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(f"ì›ë³¸ í…ìŠ¤íŠ¸ ì¼ë¶€:\n{text[:500]}...")
        return None


def normalize_column_name(col: str) -> str:
    return col.strip().replace("\u200b", "").replace("\xa0", "").replace("\t", "").replace("\n", "").replace("\r", "")


def parse_first_row_dict_from_text(response_text: str) -> dict:
    """
    LLM ì‘ë‹µì˜ ì²« ì¤„ì—ì„œ ì»¬ëŸ¼ëª… ë§¤í•‘ dictë§Œ íŒŒì‹±
    """
    first_line = response_text.strip().splitlines()[0]
    try:
        mapping = ast.literal_eval(first_line)
        if isinstance(mapping, dict):
            return mapping
        else:
            raise ValueError("íŒŒì‹±ëœ ê²°ê³¼ê°€ dictê°€ ì•„ë‹™ë‹ˆë‹¤.")
    except Exception as e:
        raise ValueError(f"ì»¬ëŸ¼ ë§¤í•‘ íŒŒì‹± ì‹¤íŒ¨: {e}")


def save_metadata(col_info: dict, save_path: str, sqlite_path: str):
    base_name = os.path.splitext(os.path.basename(sqlite_path))[0]
    meta_path = os.path.join(save_path, f"{base_name}_meta.json")

    metadata = {
        "created_at": datetime.now().isoformat(),
        "column_mapping": col_info
    }

    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    print(f"âœ… DB ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_path}")


def save_sqlite(df: pd.DataFrame, save_path: str, file_name: str) -> str:
    """
    DataFrameì„ SQLite íŒŒì¼ë¡œ ì €ì¥í•˜ê³ , ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•œë‹¤.
    íŒŒì¼ëª…ì€ í˜„ì¬ ì‹œê° ê¸°ë°˜ìœ¼ë¡œ ìë™ ìƒì„±ë¨.
    """
    file_path = os.path.join(save_path, f"{file_name}.sqlite")

    table_name = "data"  # ê¸°ë³¸ í…Œì´ë¸”ëª…

    with sqlite3.connect(file_path) as conn:
        df.to_sql(table_name, conn, index=False, if_exists="replace")

    print(f"âœ… SQLite íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path}")
    return file_path

""" VibeCraft Claude MCP Pipeline Client (Dynamic Control Version) """
__author__ = "Se Hoon Kim(sehoon787@korea.ac.kr)"

import asyncio
from typing import Optional
from contextlib import AsyncExitStack
from dotenv import load_dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from anthropic import Anthropic
from openai import OpenAI
from google import genai

load_dotenv()


class VibeCraftPipelineClient:
    def __init__(self):
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        self.anthropic = Anthropic()
        self.openai = OpenAI()
        self.google = genai.Client()

    async def connect_to_server(self, server_path: str):
        await self.exit_stack.aclose()  # ì—°ê²° ì´ˆê¸°í™”
        self.exit_stack = AsyncExitStack()

        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(
            StdioServerParameters(command="npx", args=[server_path])
        ))
        self.stdio, self.write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))
        await self.session.initialize()
        tools = await self.session.list_tools()
        print(f"\nğŸ”Œ Connected to {server_path} with tools: {[t.name for t in tools.tools]}")

    async def call_claude_and_tools(self, user_prompt: str) -> (str, bool, bool):
        messages = [{"role": "user", "content": user_prompt}]
        tools = await self.session.list_tools()
        available_tools = [{
            "name": t.name,
            "description": t.description,
            "input_schema": t.inputSchema
        } for t in tools.tools]

        response = await self.google.aio.models.generate_content(
            model="gemini-2.0-flash",
            contents="Roll 3 dice!",
            config=genai.types.GenerateContentConfig(
                temperature=0,
                tools=[self.session],  # Pass the FastMCP client session
            ),
        )
        print(response.text)

        response = self.anthropic.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=1000,
            messages=messages,
            tools=available_tools
        )

        final_text = []
        go_back = False
        redo = False

        for item in response.content:
            if item.type == "text":
                text = item.text.lower()
                final_text.append(item.text)
                if any(k in text for k in ["ë‹¤ì‹œ", "ë³€ê²½", "ì·¨ì†Œ", "redo", "re-do"]):
                    redo = True
                elif any(k in text for k in ["ì´ì „", "go back", "ë˜ëŒë¦¬ê¸°", "undo"]):
                    go_back = True
            elif item.type == "tool_use":
                tool_result = await self.session.call_tool(item.name, item.input)
                messages.append({"role": "assistant", "content": [item]})
                messages.append({
                    "role": "user",
                    "content": [{
                        "type": "tool_result",
                        "tool_use_id": item.id,
                        "content": tool_result.content
                    }]
                })
                # Recursive follow-up
                follow_up = self.anthropic.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=1000,
                    messages=messages,
                    tools=available_tools
                )
                for follow_item in follow_up.content:
                    if follow_item.type == "text":
                        text = follow_item.text.lower()
                        final_text.append(follow_item.text)
                        if any(k in text for k in ["ë‹¤ì‹œ", "ë³€ê²½", "ì·¨ì†Œ"]):
                            redo = True
                        elif any(k in text for k in ["ì´ì „", "ë˜ëŒë¦¬ê¸°"]):
                            go_back = True

        return "\n".join(final_text), redo, go_back

    async def run_pipeline(self, topic_prompt: str):
        stage = 1  # 1: topic, 2: data, 3: code
        history = {
            1: topic_prompt,
            2: "ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì›¹ì—ì„œ ìˆ˜ì§‘í•´ ì£¼ì„¸ìš”.",
            3: "ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ëŠ” ì›¹í˜ì´ì§€ ì½”ë“œë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”."
        }

        while stage <= 3:
            try:
                if stage == 1:
                    print(f"\n[Step 1] Topic ì„¤ì • ë‹¨ê³„")
                    await self.connect_to_server("@aakarsh-sasi/memory-bank-mcp")
                elif stage == 2:
                    print(f"\n[Step 2] ë°ì´í„° ìˆ˜ì§‘ ë˜ëŠ” ì—…ë¡œë“œ ë‹¨ê³„")
                    await self.connect_to_server("vibecraft_data_upload")
                elif stage == 3:
                    print(f"\n[Step 3] ì½”ë“œ ìƒì„± ë‹¨ê³„")
                    await self.connect_to_server("vibecraft_code_generator")

                result, redo, go_back = await self.call_claude_and_tools(history[stage])
                print(f"\nğŸ“Œ Claude ì‘ë‹µ:\n{result}")

                if go_back:
                    print("ğŸ”„ ì´ì „ ë‹¨ê³„ë¡œ ë˜ëŒì•„ê°‘ë‹ˆë‹¤.")
                    stage = max(1, stage - 1)
                elif redo:
                    print("â™»ï¸ í˜„ì¬ ë‹¨ê³„ë¥¼ ë‹¤ì‹œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
                    continue
                else:
                    stage += 1

            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break

    async def cleanup(self):
        await self.exit_stack.aclose()


async def main():
    client = VibeCraftPipelineClient()
    try:
        topic_prompt = input("ğŸ¤ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        await client.run_pipeline(topic_prompt)
    finally:
        await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())

__author__ = "Se Hoon Kim(sehoon787@korea.ac.kr)"

# Standard imports
import os
from typing import Dict, Any

# Third-party imports
from langchain_mcp_adapters.client import MultiServerMCPClient
from sse_starlette import ServerSentEvent

# Custom imports
from mcp_agent.client import VibeCraftAgentRunner
from mcp_agent.engine import (
    ClaudeEngine,
    OpenAIEngine,
    GeminiEngine
)
from mcp_agent.schemas.prompt_parser_schemas import VisualizationType
from schemas import SSEEventBuilder
from mcp_agent.schemas import (
    MCPServerConfig,
    VisualizationRecommendationResponse
)
from utils import FileUtils, PathUtils
from utils.menus import *
from utils.prompts import *


class VibeCraftClient:
    def __init__(self, engine: str):
        if engine == "claude":
            self.engine = ClaudeEngine()
        elif engine == "gemini":
            self.engine = GeminiEngine()
        elif engine == "gpt":
            self.engine = OpenAIEngine()
        else:
            raise ValueError("Not Supported Engine")
        self.client: Optional[MultiServerMCPClient] = None

        self.mcp_tools: Optional[List[MCPServerConfig]] = None  # common MCP tools
        self.topic_mcp_server: Optional[List[MCPServerConfig]] = None
        self.set_data_mcp_server: Optional[List[MCPServerConfig]] = None  # TODO: WIP
        self.deploy_mcp_server: Optional[List[MCPServerConfig]] = None  # TODO: WIP

        self.tools: Optional[List] = None

        self.data: Optional[pd.DataFrame] = None

    """Engine Methods"""
    def get_thread_id(self) -> str:
        return str(self.engine.thread_id)

    def merge_chat_history(self, thread_id: str):
        self.engine.merge_chat_history(thread_id=thread_id)

    def load_chat_history(self, thread_id: str):
        self.engine.load_chat_history(thread_id=thread_id)

    async def load_tools(self, mcp_servers: Optional[List[MCPServerConfig]] = None):
        """
        Connect Multiple MCP servers with ClientSessionGroup, and integrate tools, prompts, resources.
        Save self.session
        """

        mcp_servers = mcp_servers or self.mcp_tools
        if mcp_servers:
            try:
                self.client = MultiServerMCPClient(
                    {
                        tool.name: {
                            "command": tool.command,
                            "args": tool.args,
                            "transport": tool.transport
                        }
                        for tool in mcp_servers
                    }
                )
                self.tools = await self.client.get_tools()
                self.engine.update_tools(self.tools)
                print(f"\nğŸ”Œ Connected to {', '.join([t.name for t in mcp_servers])}")
                print("Connected to server with tools:", [tool.name for tool in self.tools])
            except Exception as e:
                print(f"âš ï¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {', '.join([t.name for t in mcp_servers])} - {e}")

    async def execute_step(
        self, prompt: str, system: Optional[str] = None,
        use_langchain: Optional[bool] = True,
    ) -> str:
        if use_langchain:
            return await self.engine.generate_langchain(prompt=prompt, system=system)
        return await self.engine.generate(prompt=prompt)

    async def execute_stream_step(
        self, prompt: str, system: Optional[str] = None,
        use_langchain: Optional[bool] = True,
    ):
        if use_langchain:
            async for chunk in self.engine.stream_generate_langchain(
                    prompt=prompt, system=system
            ):
                yield chunk
        else:
            async for chunk in self.engine.stream_generate(prompt=prompt):
                yield chunk

    def get_summary(self) -> str:
        stats = self.engine.get_conversation_stats()
        if stats['has_summary']:
            return stats["summary"]
        else:
            self.engine.trigger_summarize()
            stats = self.engine.get_conversation_stats()
            return stats["summary"]

    """Topic Selection Methods"""
    async def topic_selection(self, topic_prompt: str):
        await self.load_tools(self.topic_mcp_server)

        print("\nğŸš¦ Step 1: ì£¼ì œ ì„¤ì •")
        system, human = set_topic_prompt(topic_prompt)
        result = await self.execute_step(human, system)
        print(result)

    async def topic_selection_menu_handler(self):
        selected_option = input(f"\n{topic_selection_menu()}\n").strip()

        if selected_option == "1":
            await self.set_data(cli=True)
        elif selected_option == "2":
            additional_query = input("âœï¸ ì¶”ê°€ ìˆ˜ì • ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: ")
            result = await self.execute_step(additional_query)
            print(result)
        elif selected_option == "3":
            self.engine.clear_memory()
            new_prompt = input("ğŸ¤ ìƒˆë¡œìš´ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
            result = self.topic_selection(new_prompt)
            print(result)
        else:
            print("âš ï¸ ìœ íš¨í•œ ì„ íƒì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1, 2, 3)")

    async def stream_topic_selection(self, topic_prompt: str):
        await self.load_tools(self.topic_mcp_server)

        system, human = set_topic_prompt(topic_prompt)
        async for event, chunk in self.execute_stream_step(human, system):
            yield ServerSentEvent(event=event, data=chunk)
        yield SSEEventBuilder.create_menu_event(topic_selection_menu())

    """Data loading and generation Methods"""
    async def set_data(
        self, file_path: Optional[str] = None, cli: bool = False
    ):
        await self.load_tools(self.set_data_mcp_server)

        selected_option = None
        if cli:
            file_path = None
            selected_option = select_data_loader_menu()

        if selected_option == "1" or file_path:
            self.upload_data(file_path)
        else:
            self.data = await self.generate_data()

        await self.data_save(self.data, [])

    async def generate_data(self) -> pd.DataFrame:
        print("\nğŸš¦ Step 2-1: ì£¼ì œ ê¸°ë°˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±")
        system, human = generate_sample_prompt()
        sample_data = await self.execute_step(human, system)
        df = FileUtils.markdown_table_to_df(sample_data)

        return df

    def upload_data(self, file_path: Optional[str] = None):
        print("\nğŸš¦ Step 2-1: ë°ì´í„° ì—…ë¡œë“œ")

        if file_path:
            self.data = FileUtils.load_local_files([file_path])
        else:
            self.data = FileUtils.load_files()

    """Data processing Methods"""
    async def data_processing(self, df: Optional[pd.DataFrame] = None):
        """ë°ì´í„° ì „ì²˜ë¦¬ ë° ì»¬ëŸ¼ ì¶”ì²œ"""
        if df is None:
            df = self.data

        # 1. ë°ì´í„° ì „ì²˜ë¦¬
        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
        df.columns = [FileUtils.normalize_column_name(col) for col in df.columns]
        print(f"\nğŸ“Š ìµœì¢… ë°ì´í„°í”„ë ˆì„ ìš”ì•½:\n{df.head(3).to_string(index=False)}")

        # 2. ì»¬ëŸ¼ ì‚­ì œ ì¶”ì²œ
        system, human = recommend_removal_column_prompt(df)
        print("\nğŸ§¹ ì»¬ëŸ¼ ì‚­ì œ ì¶”ì²œ ìš”ì²­ ì¤‘...")
        suggestion = await self.execute_step(human, system)
        print(f"\nğŸ¤– ì¶”ì²œëœ ì»¬ëŸ¼ ëª©ë¡:\n{suggestion}")

        return df, suggestion

    async def data_save(self, df: pd.DataFrame, to_drop: List[str]):
        """ë°ì´í„° ì €ì¥ ì²˜ë¦¬"""
        print("\nğŸ’¾ SQLite í…Œì´ë¸”í™” ìš”ì²­ ì¤‘...")
        system, human = df_to_sqlite_with_col_filter_prompt(df, to_drop)
        result = await self.execute_step(human, system)
        print(f"Mapped Column dictionary: {result}")

        new_col = FileUtils.parse_dict_flexible(result)
        filtered_new_col = {k: v for k, v in new_col.items() if v is not None}

        mapped_df = df.rename(columns=new_col)[list(filtered_new_col.values())]
        print(f"\nğŸ§± Mapped Result:\n{mapped_df.head(3).to_string(index=False)}")

        # íŒŒì¼ ì €ì¥
        path = PathUtils.generate_path(self.get_thread_id())
        mapped_df.to_csv(os.path.join(path, f"{self.get_thread_id()}.csv"), encoding="cp949", index=False)
        file_path = FileUtils.save_sqlite(mapped_df, path, self.get_thread_id())
        FileUtils.save_metadata(filtered_new_col, path, file_path)

    async def data_handler(self, df: Optional[pd.DataFrame] = None) -> bool:
        """ë°ì´í„° ì²˜ë¦¬ ë©”ë‰´ í•¸ë“¤ëŸ¬"""

        print("\nğŸš¦ Step 2-2: ë°ì´í„° ìˆ˜ì •")

        is_running = True

        if df is None:
            df = self.data
        df, suggestion = await self.data_processing(df)

        selected_option = input(f"\n{select_edit_col_menu()}\n").strip()

        if selected_option == "1":
            columns_line = suggestion.splitlines()[0]
            to_drop = [col.strip() for col in columns_line.split(",")]
        elif selected_option == "2":
            print(f"\nğŸ§¹ í˜„ì¬ ì»¬ëŸ¼ ëª©ë¡:\n{', '.join(df.columns)}")
            drop_input = input("ì‚­ì œí•  ì»¬ëŸ¼ëª…ì„ ì‰¼í‘œ(,)ë¡œ ì…ë ¥ (Enter ì…ë ¥ ì‹œ ê±´ë„ˆëœ€): ").strip()
            to_drop = [col.strip() for col in drop_input.split(",")] if drop_input else []
        else:
            print("ì»¬ëŸ¼ ì‚­ì œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            to_drop = []
            is_running = False

        await self.data_save(df, to_drop)

        return is_running

    async def stream_data_processing(self, df: Optional[pd.DataFrame] = None):
        """ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ë°ì´í„° ì²˜ë¦¬"""
        if df is None:
            df = self.data

        if df is None:
            yield SSEEventBuilder.create_error_event("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë°ì´í„° ì „ì²˜ë¦¬
        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
        df.columns = [FileUtils.normalize_column_name(col) for col in df.columns]

        yield SSEEventBuilder.create_data_event(
            f"ğŸ“Š ìµœì¢… ë°ì´í„°í”„ë ˆì„ ìš”ì•½:\n{df.head(3).to_string(index=False)}"
        )

        # ì»¬ëŸ¼ ì‚­ì œ ì¶”ì²œ ìŠ¤íŠ¸ë¦¬ë°
        system, human = recommend_removal_column_prompt(df)
        async for event, chunk in self.execute_stream_step(human, system):
            yield ServerSentEvent(event=event, data=chunk)
        yield SSEEventBuilder.create_data_event(', '.join(df.columns))
        yield SSEEventBuilder.create_menu_event(select_edit_col_menu())

    async def stream_data_handler(
        self, query: str,
        df: Optional[pd.DataFrame] = None, meta: Optional[dict] = None,
    ):
        """ë°ì´í„° ì²˜ë¦¬ ë©”ë‰´ í•¸ë“¤ëŸ¬"""

        print("\nğŸš¦ Step 2-2: ë°ì´í„° ìˆ˜ì •")

        if df is None:
            df = self.data

        system, human = parse_removal_column_prompt(df, query, meta)
        suggestion = await self.execute_step(human, system)
        columns_line = suggestion.splitlines()[0]
        to_drop = [col.strip() for col in columns_line.split(",")]

        await self.data_save(df, to_drop)
        yield SSEEventBuilder.create_menu_event(additional_select_edit_col_menu())

    async def recommend_visualization_type(self) -> VisualizationRecommendationResponse:
        print("\nğŸš¦ Step 2-3: ì£¼ì œì™€ ë°ì´í„° ê¸°ë°˜ ì‹œê°í™” ë°©ì‹ ì„¤ì •")

        stats = self.engine.get_conversation_stats()
        if stats['has_summary']:
            user_context = stats["summary"]
        else:
            self.engine.trigger_summarize()
            stats = self.engine.get_conversation_stats()
            user_context = stats["summary"]

        system, human = recommend_visualization_template_prompt(self.data, user_context)
        result = await self.execute_step(human, system)

        recommendations = FileUtils.parse_visualization_recommendation(result)
        return VisualizationRecommendationResponse(
            user_context=user_context,
            recommendations=recommendations
        )

    """Code Generator Methods"""
    def run_code_generator(
            self, thread_id: str, visualization_type: VisualizationType
    ) -> Dict[str, Any]:
        """ë™ê¸° ë°©ì‹ ì½”ë“œ ìƒì„±"""
        print("\nğŸš¦ Step 3: ì›¹ì•± ì½”ë“œ ìƒì„±")

        runner = VibeCraftAgentRunner()
        file_name = f"{thread_id}.sqlite"

        if not runner.is_available() or not PathUtils.is_exist(thread_id, file_name):
            return {"success": False, "message": "ì „ì œ ì¡°ê±´ í™•ì¸ ì‹¤íŒ¨"}

        file_path = PathUtils.get_path(thread_id, file_name)[0]
        output_dir = f"./output/{thread_id}"

        try:
            result = runner.run_agent(
                sqlite_path=file_path,
                visualization_type=visualization_type,
                user_prompt=self.get_summary(),
                output_dir=output_dir
            )

            if result["success"]:
                print(f"âœ… ì½”ë“œ ìƒì„± ì™„ë£Œ: {result['output_dir']}")

            return result
        except Exception as e:
            return {"success": False, "message": str(e)}

    async def stream_run_code_generator(
            self, thread_id: str, visualization_type: VisualizationType
    ):
        """ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ì½”ë“œ ìƒì„± (SSEìš©)"""

        yield SSEEventBuilder.create_info_event("ğŸš¦ Step 3: ì›¹ì•± ì½”ë“œ ìƒì„± ì‹œì‘")

        runner = VibeCraftAgentRunner()
        file_name = f"{thread_id}.sqlite"

        # ì „ì œ ì¡°ê±´ í™•ì¸
        if not runner.is_available():
            yield SSEEventBuilder.create_error_event("vibecraft-agentë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        if not PathUtils.is_exist(thread_id, file_name):
            yield SSEEventBuilder.create_error_event(f"SQLite íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_name}")
            return

        yield SSEEventBuilder.create_info_event("âœ… ì‚¬ì „ ê²€ì¦ ì™„ë£Œ")

        file_path = PathUtils.get_path(thread_id, file_name)[0]
        output_dir = f"./output/{thread_id}"

        try:
            async for event in runner.run_agent_async(
                    sqlite_path=file_path,
                    visualization_type=visualization_type,
                    user_prompt=self.get_summary(),
                    output_dir=output_dir
            ):
                # ì´ë²¤íŠ¸ íƒ€ì…ë³„ SSE ë³€í™˜
                event_type = event.get("type", "info")
                message = event.get("message", "")

                if event_type == "error":
                    yield SSEEventBuilder.create_error_event(message)
                elif event_type == "stdout":
                    yield SSEEventBuilder.create_ai_message_chunk(message)
                elif event.get("step") == "execution_complete":
                    yield SSEEventBuilder.create_info_event("ğŸ‰ ì›¹ì•± ì½”ë“œ ìƒì„± ì™„ë£Œ!")
                    yield SSEEventBuilder.create_complete_event(thread_id)
                    return
                else:
                    yield SSEEventBuilder.create_ai_message_chunk(message)

        except Exception as e:
            yield SSEEventBuilder.create_error_event(f"ì½”ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

    """Deploy Methods"""
    # TODO: WIP
    async def step_deploy(self):
        await self.load_tools(self.deploy_mcp_server)

        print("\nğŸš¦ Step 4: Deploy")
        result = await self.execute_step("WIP")
        print(f"\nğŸ’» ë°°í¬ì¤‘...")

    async def run_pipeline(self, topic_prompt: str):
        # Step: 1
        await self.topic_selection(topic_prompt)
        self.engine.trigger_summarize()
        stats = self.engine.get_conversation_stats()
        if stats['has_summary']:
            print(f"Summary Preview: {stats['summary_preview']}")
        # Step: 2-1
        while self.data is None:
            await self.topic_selection_menu_handler()
        # Step: 2-2
        while await self.data_handler():
            pass
        # Step: 2-3
        v_type = (await self.recommend_visualization_type()).get_top_recommendation()
        # Step: 3
        result = self.run_code_generator(self.get_thread_id(), v_type.visualization_type)
        breakpoint()
        # await self.step_deploy()

    async def test(self):
        print("ğŸ”¥ Run Test...")
        prompt = "ì£¼ì œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í•´ì¤˜"

        # Run without Langchain
        result0 = await self.execute_step(prompt, use_langchain=False)
        print(f"\nğŸ¤– Run without tool and Langchain:\n{result0}\n")

        # Run Langchain
        result1 = await self.execute_step(prompt)
        print(f"\nğŸ¤– Langchain without tool:\n{result1}\n")

        while True:
            query = input("\nì‚¬ìš©ì: ").strip()
            result = await self.execute_step(query)
            print(result)

            self.engine.save_chat_history()
            self.merge_chat_history(thread_id="0d11b676-9cc5-4eb2-a90e-59277ca590fa")
            self.load_chat_history(thread_id="0d11b676-9cc5-4eb2-a90e-59277ca590fa")

    async def cleanup(self):
        self.client = None

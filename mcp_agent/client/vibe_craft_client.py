__author__ = "Se Hoon Kim(sehoon787@korea.ac.kr)"

# Standard imports
import os
from typing import Dict, Any

# Third-party imports
from langchain_mcp_adapters.client import MultiServerMCPClient
from sse_starlette import ServerSentEvent

# Custom imports
from mcp_agent.client import VibeCraftAgentRunner
from mcp_agent.engine import (
    ClaudeEngine,
    OpenAIEngine,
    GeminiEngine
)
from mcp_agent.schemas.prompt_parser_schemas import VisualizationType
from schemas import SSEEventBuilder, SSEEventType
from mcp_agent.schemas import (
    MCPServerConfig,
    VisualizationRecommendationResponse
)
from utils import FileUtils, PathUtils
from utils.prompts import *


class VibeCraftClient:
    def __init__(self, engine: str):
        if engine == "claude":
            self.engine = ClaudeEngine()
        elif engine == "gemini":
            self.engine = GeminiEngine()
        elif engine == "gpt":
            self.engine = OpenAIEngine()
        else:
            raise ValueError("Not Supported Engine")
        self.client: Optional[MultiServerMCPClient] = None

        self.mcp_tools: Optional[List[MCPServerConfig]] = None  # common MCP tools
        self.topic_mcp_server: Optional[List[MCPServerConfig]] = None
        self.set_data_mcp_server: Optional[List[MCPServerConfig]] = None  # TODO: WIP

        self.tools: Optional[List] = None

        self.data: Optional[pd.DataFrame] = None

    """Engine Methods"""
    def get_thread_id(self) -> str:
        return str(self.engine.thread_id)

    def merge_chat_history(self, thread_id: str):
        self.engine.merge_chat_history(thread_id=thread_id)

    def load_chat_history(self, thread_id: str):
        self.engine.load_chat_history(thread_id=thread_id)

    async def load_tools(self, mcp_servers: Optional[List[MCPServerConfig]] = None):
        """
        Connect Multiple MCP servers with ClientSessionGroup, and integrate tools, prompts, resources.
        Save self.session
        """

        mcp_servers = mcp_servers or self.mcp_tools
        if mcp_servers:
            try:
                self.client = MultiServerMCPClient(
                    {
                        tool.name: {
                            "command": tool.command,
                            "args": tool.args,
                            "transport": tool.transport
                        }
                        for tool in mcp_servers
                    }
                )
                self.tools = await self.client.get_tools()
                self.engine.update_tools(self.tools)
                print(f"\nğŸ”Œ Connected to {', '.join([t.name for t in mcp_servers])}")
                print("Connected to server with tools:", [tool.name for tool in self.tools])
            except Exception as e:
                print(f"âš ï¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {', '.join([t.name for t in mcp_servers])} - {e}")

    async def execute_step(
        self, prompt: str, system: Optional[str] = None,
        use_langchain: Optional[bool] = True,
    ) -> str:
        if use_langchain:
            return await self.engine.generate_langchain(prompt=prompt, system=system)
        return await self.engine.generate(prompt=prompt)

    async def execute_stream_step(
        self, prompt: str, system: Optional[str] = None,
        use_langchain: Optional[bool] = True,
    ):
        if use_langchain:
            async for chunk in self.engine.stream_generate_langchain(
                    prompt=prompt, system=system
            ):
                yield chunk
        else:
            async for chunk in self.engine.stream_generate(prompt=prompt):
                yield chunk

    def get_summary(self) -> str:
        stats = self.engine.get_conversation_stats()
        if stats['has_summary']:
            return stats["summary"]
        else:
            self.engine.trigger_summarize()
            stats = self.engine.get_conversation_stats()
            return stats["summary"]

    """Topic Selection Methods"""
    async def topic_selection(self, topic_prompt: str) -> str:
        """Step 1: ì£¼ì œ ì„¤ì •"""
        await self.load_tools(self.topic_mcp_server)

        print("\nğŸš¦ Step 1: ì£¼ì œ ì„¤ì •")
        system, human = set_topic_prompt(topic_prompt)
        result = await self.execute_step(human, system)
        print(result)
        return result

    async def stream_topic_selection(self, topic_prompt: str):
        """Step 1: ì£¼ì œ ì„¤ì • (ìŠ¤íŠ¸ë¦¬ë°)"""
        await self.load_tools(self.topic_mcp_server)

        system, human = set_topic_prompt(topic_prompt)
        async for event, chunk in self.execute_stream_step(human, system):
            yield ServerSentEvent(event=event, data=chunk)

    """Data loading and generation Methods"""
    def upload_data(self, file_path: str):
        print("\nğŸš¦ Step 2-1: ë°ì´í„° ì—…ë¡œë“œ")

        if file_path:
            self.data = FileUtils.load_local_files([file_path])
        else:
            self.data = FileUtils.load_files()

    async def set_data(self, file_path: str) -> pd.DataFrame:
        """Step 2: ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        await self.load_tools(self.set_data_mcp_server)
        self.upload_data(file_path)

        # ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥
        await self.auto_process_and_save_data()

        return self.data

    async def stream_set_data(self, file_path: str = None):
        """Step 2: ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        await self.load_tools(self.set_data_mcp_server)
        self.upload_data(file_path)

        # ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥
        async for event in self.stream_auto_process_and_save_data():
            yield event

    """Data processing Methods"""
    async def auto_process_and_save_data(self, df: Optional[pd.DataFrame] = None) -> pd.DataFrame:
        """Step 3: ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥ (ë‹¨ì¼ í”„ë¡¬í”„íŠ¸)"""
        if df is None:
            df = self.data

        print("\nğŸš¦ Step 3: ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥")

        # 1. ë°ì´í„° ì „ì²˜ë¦¬
        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
        df.columns = [FileUtils.normalize_column_name(col) for col in df.columns]
        print(f"\nğŸ“Š ë°ì´í„°í”„ë ˆì„ ì •ì œ ì™„ë£Œ:\n{df.head(3).to_string(index=False)}")

        # 2. ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¡œ ì»¬ëŸ¼ ì‚­ì œ + ì˜ë¬¸ ë³€í™˜ í•œë²ˆì— ì²˜ë¦¬
        print("\nğŸ§¹ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° ë° ì˜ë¬¸ ë³€í™˜ ì¤‘...")
        system, human = auto_process_data_prompt(df)
        result = await self.execute_step(human, system)
        print(f"\nğŸ¤– Agent ì²˜ë¦¬ ê²°ê³¼:\n{result}")

        # 3. ê²°ê³¼ íŒŒì‹± ë° ì ìš©
        new_col = FileUtils.parse_dict_flexible(result)
        filtered_new_col = {k: v for k, v in new_col.items() if v is not None}

        # ì»¬ëŸ¼ ë§¤í•‘ ì ìš© (dictionaryì— ì—†ëŠ” ì»¬ëŸ¼ì€ ìë™ ì œê±°ë¨)
        mapped_df = df.rename(columns=new_col)[list(filtered_new_col.values())]
        print(f"\nğŸ§± ìµœì¢… ë°ì´í„°:\n{mapped_df.head(3).to_string(index=False)}")

        # 4. íŒŒì¼ ì €ì¥
        path = PathUtils.generate_path(self.get_thread_id())
        mapped_df.to_csv(os.path.join(path, f"{self.get_thread_id()}.csv"), encoding="cp949", index=False)
        file_path = FileUtils.save_sqlite(mapped_df, path, self.get_thread_id())
        FileUtils.save_metadata(filtered_new_col, path, file_path)
        self.data = mapped_df

        return mapped_df

    async def stream_auto_process_and_save_data(self, df: Optional[pd.DataFrame] = None):
        """Step 3: ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥ (ìŠ¤íŠ¸ë¦¬ë°, ë‹¨ì¼ í”„ë¡¬í”„íŠ¸)"""
        if df is None:
            df = self.data

        if df is None:
            yield SSEEventBuilder.create_error_event("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        yield SSEEventBuilder.create_info_event("ğŸš¦ Step 3: ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥")

        # 1. ë°ì´í„° ì „ì²˜ë¦¬
        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
        df.columns = [FileUtils.normalize_column_name(col) for col in df.columns]
        yield SSEEventBuilder.create_data_event(
            f"ğŸ“Š ë°ì´í„°í”„ë ˆì„ ì •ì œ ì™„ë£Œ:\n{df.head(3).to_string(index=False)}"
        )

        # 2. ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¡œ ì»¬ëŸ¼ ì‚­ì œ + ì˜ë¬¸ ë³€í™˜ í•œë²ˆì— ì²˜ë¦¬
        yield SSEEventBuilder.create_info_event("ğŸ§¹ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° ë° ì˜ë¬¸ ë³€í™˜ ì¤‘...")
        system, human = auto_process_data_prompt(df)
        result_parts = []
        async for event, chunk in self.execute_stream_step(human, system):
            result_parts.append(chunk)
            yield ServerSentEvent(event=event, data=chunk)

        result = ''.join(result_parts)

        # 3. ê²°ê³¼ íŒŒì‹± ë° ì ìš©
        new_col = FileUtils.parse_dict_flexible(result)
        filtered_new_col = {k: v for k, v in new_col.items() if v is not None}

        # ì»¬ëŸ¼ ë§¤í•‘ ì ìš© (dictionaryì— ì—†ëŠ” ì»¬ëŸ¼ì€ ìë™ ì œê±°ë¨)
        mapped_df = df.rename(columns=new_col)[list(filtered_new_col.values())]
        yield SSEEventBuilder.create_data_event(
            f"ğŸ§± ìµœì¢… ë°ì´í„°:\n{mapped_df.head(3).to_string(index=False)}"
        )

        # 4. íŒŒì¼ ì €ì¥
        path = PathUtils.generate_path(self.get_thread_id())
        mapped_df.to_csv(os.path.join(path, f"{self.get_thread_id()}.csv"), encoding="cp949", index=False)
        file_path = FileUtils.save_sqlite(mapped_df, path, self.get_thread_id())
        FileUtils.save_metadata(filtered_new_col, path, file_path)
        self.data = mapped_df

        yield SSEEventBuilder.create_info_event("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")

    """Code Generator Methods"""
    async def auto_recommend_visualization_type(self) -> VisualizationType:
        """Step 4: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •"""
        print("\nğŸš¦ Step 4: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •")

        stats = self.engine.get_conversation_stats()
        if stats['has_summary']:
            user_context = stats["summary"]
        else:
            self.engine.trigger_summarize()
            stats = self.engine.get_conversation_stats()
            user_context = stats["summary"]

        system, human = recommend_visualization_template_prompt(self.data, user_context)
        result = await self.execute_step(human, system)

        recommendations = FileUtils.parse_visualization_recommendation(result)
        response = VisualizationRecommendationResponse(
            user_context=user_context,
            recommendations=recommendations
        )

        # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì‹œê°í™” íƒ€ì… ìë™ ì„ íƒ
        top_recommendation = response.get_top_recommendation()
        print(f"ğŸ’¡ ìë™ ì„ íƒëœ ì‹œê°í™” íƒ€ì…: {top_recommendation.visualization_type} (ì‹ ë¢°ë„: {top_recommendation.confidence}%)")

        return top_recommendation.visualization_type

    def run_code_generator(
            self, thread_id: str, visualization_type: VisualizationType,
            project_name: str = None, model: str = "pro"
    ) -> Dict[str, Any]:
        """ë™ê¸° ë°©ì‹ ì½”ë“œ ìƒì„±"""
        print("\nğŸš¦ Step 5: ì›¹ì•± ì½”ë“œ ìƒì„±")

        runner = VibeCraftAgentRunner()
        file_name = f"{thread_id}.sqlite"

        if not runner.is_available() or not PathUtils.is_exist(thread_id, file_name):
            return {"success": False, "message": "ì „ì œ ì¡°ê±´ í™•ì¸ ì‹¤íŒ¨"}

        file_path = PathUtils.get_path(thread_id, file_name)[0]
        output_dir = f"./output/{thread_id}"

        try:
            result = runner.run_agent(
                sqlite_path=file_path,
                visualization_type=visualization_type,
                user_prompt=self.get_summary(),
                output_dir=output_dir,
                project_name=project_name or f"vibecraft-{thread_id}",
                model=model
            )

            if result["success"]:
                print(f"âœ… ì½”ë“œ ìƒì„± ì™„ë£Œ: {result['output_dir']}")

            return result
        except Exception as e:
            return {"success": False, "message": str(e)}

    async def stream_run_code_generator(
            self, thread_id: str, visualization_type: VisualizationType,
            project_name: str = None, model: str = "pro"
    ):
        """ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ì½”ë“œ ìƒì„± (SSEìš©)"""

        yield SSEEventBuilder.create_info_event("ğŸš¦ Step 6: ì›¹ì•± ì½”ë“œ ìƒì„± ì‹œì‘")

        runner = VibeCraftAgentRunner()
        file_name = f"{thread_id}.sqlite"

        # ì „ì œ ì¡°ê±´ í™•ì¸
        if not runner.is_available():
            yield SSEEventBuilder.create_error_event("vibecraft-agentë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        if not PathUtils.is_exist(thread_id, file_name):
            yield SSEEventBuilder.create_error_event(f"SQLite íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_name}")
            return

        yield SSEEventBuilder.create_info_event("âœ… ì‚¬ì „ ê²€ì¦ ì™„ë£Œ")

        file_path = PathUtils.get_path(thread_id, file_name)[0]
        output_dir = f"./output/{thread_id}"

        try:
            async for event in runner.run_agent_async(
                    sqlite_path=file_path,
                    visualization_type=visualization_type,
                    user_prompt=self.get_summary(),
                    output_dir=output_dir,
                    project_name=project_name or f"vibecraft-{thread_id}",
                    model=model
            ):
                # ì´ë²¤íŠ¸ íƒ€ì…ë³„ SSE ë³€í™˜
                event_type = event.event
                message = event.data

                if event_type == SSEEventType.ERROR.value:
                    yield SSEEventBuilder.create_error_event(message)
                elif event_type == SSEEventType.COMPLETE.value:
                    yield SSEEventBuilder.create_info_event("ğŸ‰ ì›¹ì•± ì½”ë“œ ìƒì„± ì™„ë£Œ!")
                    yield SSEEventBuilder.create_complete_event(thread_id)
                    return
                else:
                    yield SSEEventBuilder.create_ai_message_chunk(message)

        except Exception as e:
            yield SSEEventBuilder.create_error_event(f"ì½”ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

    """Pipeline Methods"""
    async def run_workflow(self):
        # Step 4: ì¸ê³¼ê´€ê³„ ë¶„ì„ (BaseEngineì—ì„œ ìë™ìœ¼ë¡œ RAG í™œìš©)
        print("\nğŸš¦ Step 4: ë°ì´í„° ì¸ê³¼ê´€ê³„ ë¶„ì„")
        analysis_query = f"ë‹¤ìŒ ë°ì´í„°ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{self.data.head(10).to_string()}"
        analysis_result = await self.execute_step(analysis_query)
        print(f"\nğŸ“Š ì¸ê³¼ê´€ê³„ ë¶„ì„ ê²°ê³¼:\n{analysis_result}")

        # Step 5: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •
        v_type = await self.auto_recommend_visualization_type()

        # Step 6: ì½”ë“œ ìë™ ìƒì„±
        print(f"\nğŸ’» ì‹œê°í™” íƒ€ì… '{v_type}'ìœ¼ë¡œ ì½”ë“œ ìƒì„±ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
        result = self.run_code_generator(self.get_thread_id(), v_type)

        if result["success"]:
            print(f"\nâœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ìƒì„±ëœ ì½”ë“œ: {result['output_dir']}")
            return result
        else:
            print(f"\nâŒ ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {result['message']}")
            return result

    async def stream_run_workflow(self):
        # Step 4: ì¸ê³¼ê´€ê³„ ë¶„ì„
        yield SSEEventBuilder.create_info_event("ğŸš¦ Step 4: ë°ì´í„° ì¸ê³¼ê´€ê³„ ë¶„ì„")
        analysis_query = f"ë‹¤ìŒ ë°ì´í„°ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{self.data.head(10).to_string()}"
        async for event, chunk in self.execute_stream_step(analysis_query):
            yield ServerSentEvent(event=event, data=chunk)

        # Step 5: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •
        yield SSEEventBuilder.create_info_event("ğŸš¦ Step 5: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •")
        v_type = await self.auto_recommend_visualization_type()
        yield SSEEventBuilder.create_data_event(f"ğŸ’¡ ì„ íƒëœ ì‹œê°í™” íƒ€ì…: {v_type}")

        # Step 6: ì½”ë“œ ìë™ ìƒì„±
        async for event in self.stream_run_code_generator(self.get_thread_id(), v_type):
            yield event

    """Pipeline Test"""
    async def run_pipeline(self, topic_prompt: str, file_path: str):
        """
        ê°„ì†Œí™”ëœ ìë™ íŒŒì´í”„ë¼ì¸

        Args:
            topic_prompt: ë¶„ì„ ì£¼ì œ
            file_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        # Step 1: ì£¼ì œ ì„¤ì •
        await self.topic_selection(topic_prompt)

        # Step 2: ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” ìƒì„±
        await self.set_data(file_path)

        # ì´í›„ ìë™í™” í”„ë¡œì„¸ìŠ¤
        # Step 4: ì¸ê³¼ê´€ê³„ ë¶„ì„ (BaseEngineì—ì„œ ìë™ìœ¼ë¡œ RAG í™œìš©)
        print("\nğŸš¦ Step 4: ë°ì´í„° ì¸ê³¼ê´€ê³„ ë¶„ì„")
        analysis_query = f"ë‹¤ìŒ ë°ì´í„°ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{self.data.head(10).to_string()}"
        analysis_result = await self.execute_step(analysis_query)
        print(f"\nğŸ“Š ì¸ê³¼ê´€ê³„ ë¶„ì„ ê²°ê³¼:\n{analysis_result}")

        # Step 5: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •
        v_type = await self.auto_recommend_visualization_type()

        # Step 6: ì½”ë“œ ìë™ ìƒì„±
        print(f"\nğŸ’» ì‹œê°í™” íƒ€ì… '{v_type}'ìœ¼ë¡œ ì½”ë“œ ìƒì„±ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
        result = self.run_code_generator(self.get_thread_id(), v_type)

        if result["success"]:
            print(f"\nâœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ìƒì„±ëœ ì½”ë“œ: {result['output_dir']}")
            return result
        else:
            print(f"\nâŒ ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {result['message']}")
            return result

    async def stream_run_pipeline(self, topic_prompt: str, file_path: Optional[str] = None):
        """
        ê°„ì†Œí™”ëœ ìë™ íŒŒì´í”„ë¼ì¸ (ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            topic_prompt: ë¶„ì„ ì£¼ì œ
            file_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        """
        # Step 1: ì£¼ì œ ì„¤ì •
        yield SSEEventBuilder.create_info_event("ğŸš¦ Step 1: ì£¼ì œ ì„¤ì •")
        async for event in self.stream_topic_selection(topic_prompt):
            yield event

        # Step 2: ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” ìƒì„±
        yield SSEEventBuilder.create_info_event("ğŸš¦ Step 2: ë°ì´í„° ë¡œë“œ")
        # self.stream_set_data(file_path)
        self.stream_set_data(r"/samples/sample.csv")
        if self.data is not None:
            yield SSEEventBuilder.create_data_event(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(self.data)} rows)")

        # Step 3: ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥
        async for event in self.stream_auto_process_and_save_data():
            yield event

        # Step 4: ì¸ê³¼ê´€ê³„ ë¶„ì„
        yield SSEEventBuilder.create_info_event("ğŸš¦ Step 4: ë°ì´í„° ì¸ê³¼ê´€ê³„ ë¶„ì„")
        analysis_query = f"ë‹¤ìŒ ë°ì´í„°ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{self.data.head(10).to_string()}"
        async for event, chunk in self.execute_stream_step(analysis_query):
            yield ServerSentEvent(event=event, data=chunk)

        # Step 5: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •
        yield SSEEventBuilder.create_info_event("ğŸš¦ Step 5: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •")
        v_type = await self.auto_recommend_visualization_type()
        yield SSEEventBuilder.create_data_event(f"ğŸ’¡ ì„ íƒëœ ì‹œê°í™” íƒ€ì…: {v_type}")

        # Step 6: ì½”ë“œ ìë™ ìƒì„±
        async for event in self.stream_run_code_generator(self.get_thread_id(), v_type):
            yield event

    async def test(self):
        print("ğŸ”¥ Run Test...")
        prompt = "ì£¼ì œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í•´ì¤˜"

        # Run without Langchain
        result0 = await self.execute_step(prompt, use_langchain=False)
        print(f"\nğŸ¤– Run without tool and Langchain:\n{result0}\n")

        # Run Langchain
        result1 = await self.execute_step(prompt)
        print(f"\nğŸ¤– Langchain without tool:\n{result1}\n")

        while True:
            query = input("\nì‚¬ìš©ì: ").strip()
            result = await self.execute_step(query)
            print(result)

            self.engine.save_chat_history()
            self.merge_chat_history(thread_id="0d11b676-9cc5-4eb2-a90e-59277ca590fa")
            self.load_chat_history(thread_id="0d11b676-9cc5-4eb2-a90e-59277ca590fa")

    async def cleanup(self):
        self.client = None

__author__ = "Se Hoon Kim(sehoon787@korea.ac.kr)"

# Standard imports
import os
from typing import Optional

# Third-party imports
from langchain_mcp_adapters.client import MultiServerMCPClient
import pandas as pd
from sse_starlette import ServerSentEvent

# Custom imports
from engine import ClaudeEngine, OpenAIEngine, GeminiEngine
from schemas.mcp_schemas import MCPServerConfig
from utils import PathUtils
from utils.menus import *
from utils.prompts import *
from utils.data_loader_utils import (
    load_files,
    load_local_files,
    markdown_table_to_df,
    normalize_column_name,
    parse_first_row_dict_from_text,
    save_metadata,
    save_sqlite
)


class VibeCraftClient:
    def __init__(self, engine: str):
        if engine == "claude":
            self.engine = ClaudeEngine()
        elif engine == "gemini":
            self.engine = GeminiEngine()
        elif engine == "gpt":
            self.engine = OpenAIEngine()
        else:
            raise ValueError("Not Supported Engine")
        self.client: Optional[MultiServerMCPClient] = None

        self.mcp_tools: Optional[List[MCPServerConfig]] = None  # common MCP tools
        self.topic_mcp_server: Optional[List[MCPServerConfig]] = None
        self.web_search_mcp_server: Optional[List[MCPServerConfig]] = None  # TODO: WIP
        self.db_mcp_server: Optional[List[MCPServerConfig]] = None  # TODO: WIP
        self.deploy_mcp_server: Optional[List[MCPServerConfig]] = None  # TODO: WIP

        self.tools: Optional[List] = None

        self.data: Optional[pd.DataFrame] = None

    """Engine Methods"""
    def get_thread_id(self) -> str:
        return str(self.engine.thread_id)

    def merge_chat_history(self, thread_id: str):
        self.engine.merge_chat_history(thread_id=thread_id)

    def load_chat_history(self, thread_id: str):
        self.engine.load_chat_history(thread_id=thread_id)

    async def load_tools(self, mcp_servers: Optional[List[MCPServerConfig]] = None):
        """
        Connect Multiple MCP servers with ClientSessionGroup, and integrate tools, prompts, resources.
        Save self.session
        """

        mcp_servers = mcp_servers or self.mcp_tools
        if mcp_servers:
            try:
                self.client = MultiServerMCPClient(
                    {
                        tool.name: {
                            "command": tool.command,
                            "args": tool.args,
                            "transport": tool.transport
                        }
                        for tool in mcp_servers
                    }
                )
                self.tools = await self.client.get_tools()
                self.engine.update_tools(self.tools)
                print(f"\nğŸ”Œ Connected to {', '.join([t.name for t in mcp_servers])}")
                print("Connected to server with tools:", [tool.name for tool in self.tools])
            except Exception as e:
                print(f"âš ï¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {', '.join([t.name for t in mcp_servers])} - {e}")

    async def execute_step(
        self, prompt: str,
        use_langchain: Optional[bool] = True,
    ) -> str:
        if use_langchain:
            return await self.engine.generate_langchain(prompt=prompt)
        return await self.engine.generate(prompt=prompt)

    async def execute_stream_step(
        self, prompt: str,
        use_langchain: Optional[bool] = True,
    ):
        if use_langchain:
            async for chunk in self.engine.stream_generate_langchain(prompt=prompt):
                yield chunk
        else:
            async for chunk in self.engine.stream_generate(prompt=prompt):
                yield chunk

    """Topic Selection Methods"""
    async def topic_selection(self, topic_prompt: str):
        await self.load_tools(self.topic_mcp_server)

        print("\nğŸš¦ Step 1: ì£¼ì œ ì„¤ì •")
        prompt = set_topic_prompt(topic_prompt)
        result = await self.execute_step(prompt)
        print(result)

    async def topic_selection_menu_handler(self):
        selected_option = input(topic_selection_menu()).strip()

        if selected_option == "1":
            await self.load_data(cli=True)
        elif selected_option == "2":
            additional_query = input("âœï¸ ì¶”ê°€ ìˆ˜ì • ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: ")
            result = await self.execute_step(additional_query)
            print(result)
        elif selected_option == "3":
            self.engine.clear_memory()
            new_prompt = input("ğŸ¤ ìƒˆë¡œìš´ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
            result = self.topic_selection(new_prompt)
            print(result)
        else:
            print("âš ï¸ ìœ íš¨í•œ ì„ íƒì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1, 2, 3)")

    async def stream_topic_selection(self, topic_prompt: str):
        await self.load_tools(self.topic_mcp_server)

        prompt = set_topic_prompt(topic_prompt)
        async for event, chunk in self.execute_stream_step(prompt):
            yield ServerSentEvent(
                event=event,
                data=f"{chunk}"
            )
        yield ServerSentEvent(
            event="menu",
            data=topic_selection_menu()
        )

    async def stream_topic_selection_menu_handler(
        self,
        selected_option: str,
        query: Optional[str] = None,
    ):
        if selected_option == "1":
            await self.load_data(cli=False)
            yield ServerSentEvent(
                event="data",
                # data=f"{chunk}"
                data="[data_path]"
            )
        elif selected_option == "2":
            if query:
                async for event, chunk in self.execute_stream_step(query):
                    yield ServerSentEvent(
                        event=event,
                        data=f"{chunk}"
                    )
        elif selected_option == "3":
            self.engine.clear_memory()
            async for msg in self.stream_topic_selection(query):
                yield msg
        else:
            yield ServerSentEvent(
                event="error",
                data="âš ï¸ ìœ íš¨í•œ ì„ íƒì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1, 2, 3)"
            )

    """Data Generator and Analysis Methods"""
    # TODO: apiì™€ cli ë¡œì§ ì¬ì„¤ê³„ í•„ìš”
    async def load_data(
        self, file_path: Optional[str] = None, cli: bool = False
    ):
        selected_option = None
        if cli:
            file_path = None
            selected_option = select_data_loader_menu()

        if selected_option == "1" or file_path:
            self.data = self.upload_data(file_path)
        self.data = await self.generate_data()

    async def generate_data(self) -> pd.DataFrame:
        await self.load_tools(self.web_search_mcp_server)

        print("\nğŸš¦ Step 2: ì£¼ì œ ê¸°ë°˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±")
        prompt = generate_sample_prompt()
        sample_data = await self.execute_step(prompt)
        df = markdown_table_to_df(sample_data)

        return df

    def upload_data(self, file_path: Optional[str] = None) -> pd.DataFrame:
        print("\nğŸš¦ Step 2: ë°ì´í„° ì—…ë¡œë“œ")

        if file_path and PathUtils.is_exist(self.engine.thread_id, file_path):
            return pd.read_csv(file_path)
        else:
            return load_files()

    # TODO: refactoring
    async def data_handler(self, df: pd.DataFrame, cli: Optional[bool] = False):
        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
        df.columns = [normalize_column_name(col) for col in df.columns]

        if df is not None:
            # 1. Check data
            print(f"\nğŸ“Š ìµœì¢… ë°ì´í„°í”„ë ˆì„ ìš”ì•½:\n{df.head(3).to_string(index=False)}")

            # 2. Check columns
            removal_prompt = recommend_removal_column_prompt(df)
            print("\nğŸ§¹ ì»¬ëŸ¼ ì‚­ì œ ì¶”ì²œ ìš”ì²­ ì¤‘...")
            suggestion = await self.execute_step(removal_prompt)
            print(f"\nğŸ¤– ì¶”ì²œëœ ì»¬ëŸ¼ ëª©ë¡:\n{suggestion}")


            choice = input(select_edit_col_menu()).strip()


            if choice == "1":
                columns_line = suggestion.splitlines()[0]
                to_drop = [col.strip() for col in columns_line.split(",")]
            elif choice == "2":
                print(f"\nğŸ§¹ í˜„ì¬ ì»¬ëŸ¼ ëª©ë¡:\n{', '.join(df.columns)}")
                drop_input = input("ì‚­ì œí•  ì»¬ëŸ¼ëª…ì„ ì‰¼í‘œ(,)ë¡œ ì…ë ¥ (Enter ì…ë ¥ ì‹œ ê±´ë„ˆëœ€): ").strip()
                to_drop = [col.strip() for col in drop_input.split(",")] if drop_input else []
            else:
                print("ì»¬ëŸ¼ ì‚­ì œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                to_drop = []

            print("\nğŸ’¾ SQLite í…Œì´ë¸”í™” ìš”ì²­ ì¤‘...")
            prompt = df_to_sqlite_with_col_filter_prompt(df, to_drop)
            result = await self.execute_step(prompt)
            print(f"Mapped Column dictionary: {result}")

            new_col = parse_first_row_dict_from_text(result)
            filtered_new_col = {k: v for k, v in new_col.items() if v is not None}

            mapped_df = df.rename(columns=new_col)[list(filtered_new_col.values())]
            print(f"\nğŸ§± Mapped Result:\n{mapped_df.head(3).to_string(index=False)}")

            save_path = "./data_store"
            os.makedirs(save_path, exist_ok=True)
            df.to_csv(os.path.join(save_path, "data.csv"), encoding="cp949", index=False)
            file_path = save_sqlite(mapped_df, save_path)
            save_metadata(filtered_new_col, save_path, file_path)

            return file_path
        else:
            return await self.load_data(cli)

    """Code Generator Methods"""
    # TODO: WIP
    async def step_code_generation(self):
        # TODO: langchain chat history summary ì´í›„ cli run
        print("\nğŸš¦ Step 3: ì›¹ì•± ì½”ë“œ ìƒì„±")

    # TODO: WIP
    async def step_deploy(self):
        await self.load_tools(self.deploy_mcp_server)

        print("\nğŸš¦ Step 4: Deploy")
        result = await self.execute_step("WIP")
        print(f"\nğŸ’» ë°°í¬ì¤‘...")

    async def run_pipeline(self, topic_prompt: str):
        await self.topic_selection(topic_prompt)
        while self.data is None:
            await self.topic_selection_menu_handler()
        await self.data_handler(self.data)
        breakpoint()
        # await self.step_code_generation()
        # await self.step_deploy()

    async def test(self):
        print("ğŸ”¥ Run Test...")
        prompt = "ì£¼ì œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í•´ì¤˜"

        # Run without Langchain
        result0 = await self.execute_step(prompt, use_langchain=False)
        print(f"\nğŸ¤– Run without tool and Langchain:\n{result0}\n")

        # Run Langchain
        result1 = await self.execute_step(prompt)
        print(f"\nğŸ¤– Langchain without tool:\n{result1}\n")

        while True:
            query = input("\nì‚¬ìš©ì: ").strip()
            result = await self.execute_step(query)
            print(result)

            self.engine.save_chat_history()
            self.merge_chat_history(thread_id="0d11b676-9cc5-4eb2-a90e-59277ca590fa")
            self.load_chat_history(thread_id="0d11b676-9cc5-4eb2-a90e-59277ca590fa")

    async def cleanup(self):
        self.client = None
